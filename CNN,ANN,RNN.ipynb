{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CduAG639tdeB",
        "outputId": "a02ae488-2ca0-45c6-857f-4f8801a288d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 60s 75ms/step - loss: 1.5542 - accuracy: 0.4332\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 56s 72ms/step - loss: 1.1848 - accuracy: 0.5799\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 59s 76ms/step - loss: 1.0258 - accuracy: 0.6399\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 57s 73ms/step - loss: 0.9295 - accuracy: 0.6741\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 58s 74ms/step - loss: 0.8547 - accuracy: 0.7018\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.9103 - accuracy: 0.6853\n",
            "Test accuracy: 0.6852999925613403\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "# Load and preprocess the CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlOa9CORu0va",
        "outputId": "d0cb90b8-2ad9-4fa4-be48-3bf01432f80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 49s 122ms/step - loss: 0.6626 - accuracy: 0.6066\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 48s 123ms/step - loss: 0.4110 - accuracy: 0.8208\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 48s 124ms/step - loss: 0.3624 - accuracy: 0.8443\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 48s 122ms/step - loss: 0.3930 - accuracy: 0.8287\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 49s 125ms/step - loss: 0.4095 - accuracy: 0.8204\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 0.4632 - accuracy: 0.7993\n",
            "Test accuracy: 0.7992799878120422\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load and preprocess the IMDB dataset\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=max_features)\n",
        "train_data = sequence.pad_sequences(train_data, maxlen=maxlen)\n",
        "test_data = sequence.pad_sequences(test_data, maxlen=maxlen)\n",
        "\n",
        "# Define the RNN model\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(max_features, 32),\n",
        "    layers.SimpleRNN(32),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMCrxDTxwi55",
        "outputId": "47a1ca95-330c-454e-be46-bb7bdc3ee1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 5s 4ms/step - loss: 0.5190 - accuracy: 0.8176\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3773 - accuracy: 0.8632\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3401 - accuracy: 0.8746\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.3151 - accuracy: 0.8843\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.2970 - accuracy: 0.8911\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8725\n",
            "Test accuracy: 0.8725000023841858\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the Fashion MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the ANN model\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}